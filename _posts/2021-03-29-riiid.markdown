---
title: "Kaggle RIIID Knowledge Tracing Competition (21st Place)"
layout: post
date: 2021-03-29 10:00
tag:
  - Pytorch
  - Transformers
  - Knowledge Tracing
  - Kaggle
image: /assets/images/saint+.png
headerImage: true
projects: true
hidden: true # don't count this post in blog pagination
description: "Kaggle RIIID Knowledge Tracing Competition"
category: project
author: gautierdagan
externalLink: false
---

In this competition, the challenge was to create algorithms for "Knowledge Tracing," the modeling of student knowledge over time. The goal was to accurately predict how students will perform on future interactions. 

Using data from Riiidâ€™s EdNet, we replicated the state-of-the-art SAINT+ model proposed in [Shin, Dongmin, et. al.](https://arxiv.org/pdf/2010.12042.pdf). SAINT+ is a transformer based architecture that looks at the series of previous answers and questions given to a student using the different encoder and decoder heads to encode different parts of the information.

We augment this architecture with salient aggregate features such as a rolling average of the accuracy of the student until the timestep *t*, or the number of attempts that the student had on this specific question. These features give additional information to the network, and in some cases propagate the information that is outside the attention window.

![Saint+](/assets/images/saint+.png)

As shown in the diagram above (red boxes), we augment the encoder input with tag information and the decoder input with hand-crafted aggregate features.

Using our approach, we finished in 21st position out of 3395 teams.

You can view the full code and details on Github [here](https://github.com/gautierdag/riiid).


##### References

> Shin, Dongmin, et al. "Saint+: Integrating temporal features for ednet correctness prediction." *LAK21: 11th International Learning Analytics and Knowledge Conference*. 2021.